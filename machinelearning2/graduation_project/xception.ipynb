{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(19906)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from keras.preprocessing import image\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Activation\n",
    "from keras.layers.core import Dropout\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_im_cv2(path):\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用InceptionV3模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.xception import Xception, preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "选择作为验证集的司机ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "选择作为验证集的司机ID: ['p041' 'p056']\n"
     ]
    }
   ],
   "source": [
    "drivers_pd = pd.read_csv(\"data/driver_imgs_list.csv\")\n",
    "imgs_pd = drivers_pd[\"img\"]\n",
    "class_pd = drivers_pd[\"classname\"]\n",
    "subject_pd = drivers_pd[\"subject\"]\n",
    "choices = np.random.choice(drivers_pd[\"subject\"].drop_duplicates(), 2)\n",
    "print(\"选择作为验证集的司机ID:\", choices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按选择的司机ID分割训练集和验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分割的训练集数量: 21025 ，验证集数量: 1399\n"
     ]
    }
   ],
   "source": [
    "val_index = []\n",
    "for choice in choices:\n",
    "    val_index.extend(subject_pd[subject_pd == choice].index.tolist())\n",
    "    \n",
    "test_mask = np.zeros(np.alen(subject_pd), dtype=np.bool)\n",
    "for val_i in val_index:\n",
    "    test_mask[val_i] = True\n",
    "    \n",
    "train_index = subject_pd[np.logical_not(test_mask)].index\n",
    "print(\"分割的训练集数量:\", np.alen(train_index), \"，验证集数量:\", np.alen(val_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建图像数据处理目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def rmrf_mkdir(dirname):\n",
    "    if os.path.exists(dirname):\n",
    "        shutil.rmtree(dirname)\n",
    "    os.mkdir(dirname)\n",
    "    \n",
    "train_dir = \"data/imgs/train2\"\n",
    "val_dir = \"data/imgs/val2\"\n",
    "origin_test_dir = \"data/imgs/test\"\n",
    "test_dir = \"data/imgs/test1\"\n",
    "saved_weights = \"saved_weights\"\n",
    "if not os.path.exists(saved_weights):\n",
    "    os.mkdir(saved_weights)\n",
    "    \n",
    "# 因为加载测试集时目录中也需要有子目录，将data/imgs/test目录软链接到data/imgs/test1/test\n",
    "if not os.path.exists(test_dir):\n",
    "    os.mkdir(test_dir)\n",
    "    os.symlink('../test', test_dir+\"/test\")\n",
    "\n",
    "# 在新的训练或验证集目录中为图片创建到原位置的链接\n",
    "def link_imgs(target_dir, X, y):\n",
    "    for img_name, target in zip(X, y):\n",
    "        symlink_dir = os.path.join(target_dir, target)\n",
    "        if not os.path.exists(symlink_dir):\n",
    "            os.mkdir(symlink_dir)\n",
    "        os.symlink('../../train/'+target+'/'+img_name, symlink_dir+'/'+img_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图片预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集图像生成器\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=10.,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "# 验证集图像生成器\n",
    "val_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图像生成器输出的图像大小\n",
    "out_image_size = (299, 299)\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21025 images belonging to 10 classes.\n",
      "Found 1399 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# 删除上次K折循环分离出的训练集和验证集文件，并重新创建目录\n",
    "rmrf_mkdir(train_dir)\n",
    "rmrf_mkdir(val_dir)\n",
    "\n",
    "X_train, X_val = imgs_pd[train_index], imgs_pd[val_index]\n",
    "y_train, y_val = class_pd[train_index], class_pd[val_index]\n",
    "\n",
    "# 链接训练集到新的目录中\n",
    "link_imgs(train_dir, X_train, y_train)\n",
    "\n",
    "# 链接验证集到新的目录中\n",
    "link_imgs(val_dir, X_val, y_val)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=out_image_size,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    class_mode='categorical')\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=out_image_size,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model name: inception_v3 , will save weight file: saved_weights/inception_v3.h5\n"
     ]
    }
   ],
   "source": [
    "base_model = Xception(weights='imagenet', include_top=False)\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(10, activation='softmax', kernel_regularizer=l2(0.01))(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions, name=base_model.name)\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "163/329 [=============>................] - ETA: 9:18 - loss: 0.4737 - acc: 0.8963"
     ]
    }
   ],
   "source": [
    "# 训练代数\n",
    "epochs = 10\n",
    "\n",
    "callbacks = [EarlyStopping(monitor=\"val_loss\", verbose=1, mode=\"min\", \n",
    "                              min_delta=0.0003, patience=3)]\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练结果处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 保存权重\n",
    "save_file = saved_weights + '/' + model.name + '.h5'\n",
    "print(\"model name:\", model.name, \", will save weight file:\", save_file)\n",
    "model.save_weights(save_file)\n",
    "\n",
    "# 绘制图型\n",
    "plt.figure(figsize=(12, 24))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "\n",
    "plt.title('Training and validation loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
